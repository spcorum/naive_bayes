{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Naive Bayes Classifier Theory__\n",
    "\n",
    "The Naive Bayes classifier is generative model that seeks to model a classifier as a conditional probability, $p(C_{(k)}|\\boldsymbol{x})$, where $C_{(k)}$ is the class and $\\boldsymbol{x}$ is the data observation. From Bayes rule,\n",
    "\n",
    "$$ p(C_{(k)}|\\boldsymbol{x}) = \\frac{p(C_{(k)}) p(\\boldsymbol{x}|C_{(k)})}{p(\\boldsymbol{x})} \\propto p(C_{(k)}) p(\\boldsymbol{x}|C_{(k)}) $$\n",
    "\n",
    "The naive Bayes premise assumes that each $x_i \\in \\boldsymbol{x}$ is conditionally independent of $x_j \\in \\boldsymbol{x}$ for $i,j = 1,\\dots,n$ and $i \\neq j$. That is,\n",
    "\n",
    "$$ p(\\boldsymbol{x}|C_{(k)}) = p(x_1,\\dots,x_n|C_{(k)}) = \\prod_{i=1}^n p(x_i|C_{(k)}) $$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$ p(C_{(k)}|\\boldsymbol{x}) \\propto p(C_{(k)}) \\prod_{i=1}^n p(x_i|C_{(k)}) $$\n",
    "\n",
    "The Naive Bayes Classifier is the classifier that maximizes the likelihood of the data (the so called \\textit{maximum a posteriori} or \\textit{MAP} decision rule).\n",
    "\n",
    "$$ \\hat{y} = \\text{argmax}_{k \\in 1, \\dots, K} \\enspace p(C_{(k)}) \\prod_{i=1}^n p(x_i|C_{(k)}) $$\n",
    "\n",
    "The parametric form of $p(x_i|C_{(k)})$ is chosen from the knowledge of the data, and the data is used to calculate the parameters of $p(x_i|C_{(k)})$. For real valued data, Gaussian Naive Bayes is often used, where $p(x_i|C_{(k)})$ is taken to be Gaussian. That is,\n",
    "\n",
    "$$ p(x_i = \\hat{x}_i | C_{(k)}) =  \\frac{1}{\\sqrt{2 \\pi \\sigma_{i(k)}^2}} e^{-\\frac{\\left( \\hat{x}_i-\\mu_{i(k)} \\right)^2}{2 \\sigma_{i(k)}^2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Naive Bayes Classifier Code__\n",
    "\n",
    "I coded up the Gaussian Naive Bayes classifier in the \"gnb\" class. The code below tests the class out on a synthetic version breast cancer malignancy data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       t/p       Benign Malignant \n",
      "       Benign        34         2 \n",
      "    Malignant         5        16 \n"
     ]
    }
   ],
   "source": [
    "# Test code\n",
    "       \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from gnb import gnb # Custom Gaussian Naive Bayes class\n",
    "\n",
    "# Import cancer image features data   \n",
    "data = pd.read_csv('Data_to_applicants.csv')\n",
    "y = data.loc[:,'diagnosis']\n",
    "X_raw = data.loc[:,'radius_mean':'fractal_dimension_worst']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y, \n",
    "                                                    test_size = 0.1, \n",
    "                                                    stratify = y, \n",
    "                                                    random_state = 1001)\n",
    "X_train = pd.DataFrame(X_train, columns = X_raw.columns)\n",
    "y_train = pd.DataFrame(y_train, columns = ['diagnosis'])\n",
    "X_test = pd.DataFrame(X_test, columns = X_raw.columns)\n",
    "y_test = pd.DataFrame(y_test, columns = ['diagnosis'])\n",
    "\n",
    "# Remove missing values\n",
    "imp = IterativeImputer(max_iter=100, random_state=0)\n",
    "imp.fit(X_train)\n",
    "X_train_impute = pd.DataFrame(data = imp.transform(X_train), \n",
    "                              columns = data.columns[1:-1])\n",
    "X_test_impute = pd.DataFrame(data = imp.transform(X_test), \n",
    "                             columns = data.columns[1:-1])\n",
    "\n",
    "# Drop columns with little differential variance or high covariance with \n",
    "# other features\n",
    "drop_these = ['perimeter_mean', 'area_mean','perimeter_se', 'area_se',\n",
    "              'perimeter_worst', 'area_worst', 'smoothness_mean', \n",
    "              'fractal_dimension_mean', 'smoothness_se', \n",
    "              'compactness_se', 'concavity_se', 'concave points_se',\n",
    "              'symmetry_se', 'fractal_dimension_se',\n",
    "              'fractal_dimension_worst']\n",
    "X_train_reduced = X_train_impute.drop(columns = drop_these)\n",
    "X_test_reduced = X_test_impute.drop(columns = drop_these)                                           \n",
    "\n",
    "# Fit Gaussian Naive Bayes classifier\n",
    "classifier = gnb()\n",
    "classifier.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = classifier.predict(X_test_reduced)\n",
    "\n",
    "# Confusion matrix\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"\n",
    "    Pretty print for confusion matrixes\n",
    "\n",
    "    Reference link: https://gist.github.com/zachguo/10296432\n",
    "    \"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    \n",
    "    # Begin CHANGES\n",
    "    fst_empty_cell = (columnwidth-3)//2 * \" \" + \"t/p\" + (columnwidth-3)//2 * \" \"\n",
    "    \n",
    "    if len(fst_empty_cell) < len(empty_cell):\n",
    "        fst_empty_cell = \" \" * (len(empty_cell) - len(fst_empty_cell)) + fst_empty_cell\n",
    "    # Print header\n",
    "    print(\"    \" + fst_empty_cell, end=\" \")\n",
    "    # End CHANGES\n",
    "    \n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "        \n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1d\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()\n",
    "        \n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print_cm(cm, ['Benign', 'Malignant'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PFDS",
   "language": "python",
   "name": "pfds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
